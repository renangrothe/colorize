# ColorizaÃ§Ã£o AutomÃ¡tica de Imagens com Deep Learning
Este repositÃ³rio contÃ©m o cÃ³digo-fonte do projeto de Processamento de Imagens para a colorizaÃ§Ã£o automÃ¡tica de imagens em tons de cinza, utilizando Redes Neurais Convolucionais (CNNs). A abordagem transforma a colorizaÃ§Ã£o em um problema de classificaÃ§Ã£o multimodal, permitindo que o modelo produza cores vibrantes e realistas.

O projeto foi desenvolvido por Renan Suana Grothe Garcia e Nathalie Santos Komatsu como parte da disciplina de Processamento de Imagens na Universidade Federal de SÃ£o Carlos (UFSCar).

## ğŸ”­ VisÃ£o Geral
O objetivo central Ã©, a partir do canal de luminÃ¢ncia `(L)` de uma imagem no espaÃ§o de cor CIE Lab, prever os canais de cromaticidade `('a' e 'b')` correspondentes. O problema, inerentemente mal posto, Ã© tratado como uma tarefa de classificaÃ§Ã£o multimodal.

As principais tÃ©cnicas empregadas sÃ£o:

- **QuantizaÃ§Ã£o do EspaÃ§o de Cor:** O espaÃ§o de cor ab Ã© discretizado em 313 classes, transformando o problema de regressÃ£o em classificaÃ§Ã£o.
- **Rebalanceamento de Classes:** Uma funÃ§Ã£o de perda personalizada atribui maior peso a cores raras e vibrantes, combatendo a tendÃªncia dos modelos de produzir resultados dessaturados.
- **InferÃªncia com Annealed-Mean:** Uma tÃ©cnica para decodificar a distribuiÃ§Ã£o de probabilidade de saÃ­da, ajustando a "temperatura" `(T)` para equilibrar a vivacidade e a coerÃªncia espacial das cores.

## ğŸ—ï¸ Arquitetura do Modelo
Foram desenvolvidas e exploradas duas arquiteturas principais do tipo Encoder-Decoder:

- **ColorNet:** A arquitetura base, que utiliza uma sÃ©rie de blocos convolucionais para extrair caracterÃ­sticas da imagem em diferentes escalas.
- **ColorNetRes:** Uma versÃ£o aprimorada que incorpora blocos residuais (Residual Blocks). Essa modificaÃ§Ã£o facilita o fluxo de gradientes durante o treinamento, permitindo a construÃ§Ã£o de redes mais profundas e melhorando a capacidade de aprendizado de caracterÃ­sticas complexas.

## âš™ï¸ PrÃ©-requisitos
Para executar este projeto, vocÃª precisarÃ¡ ter o Python 3.8 (ou superior) e o gerenciador de pacotes pip instalados.

## ğŸš€ InstalaÃ§Ã£o
Siga os passos abaixo para configurar o ambiente de desenvolvimento.

1. Clone o repositÃ³rio:
```
git clone https://github.com/renangrothe/colorize.git
cd colorize
```

2. Crie e ative um ambiente virtual:
Ã‰ altamente recomendÃ¡vel usar um ambiente virtual para isolar as dependÃªncias do projeto.
```
# Criar o ambiente
python -m venv venv

# Ativar no Linux/macOS
source venv/bin/activate

# Ativar no Windows (PowerShell)
.\venv\Scripts\Activate.ps1
```

3. Instale as dependÃªncias:
Instale as bibliotecas necessÃ¡rias manualmente.
``` python
pip install torch torchvision numpy scikit-image opencv-python matplotlib
```
``` bash
> sudo pacman -S jupyter-server # ou
> sudo apt get jupyter-server
```

## Como Usar
O projeto Ã© dividido em duas etapas principais: treinamento do modelo e inferÃªncia (colorizaÃ§Ã£o de imagens).

### 1. Treinamento

Para treinar um novo modelo, vocÃª precisarÃ¡ de um dataset de imagens coloridas. O projeto foi treinado originalmente com o ImageWoof, um subconjunto do ImageNet. Dentro do diretÃ³rio data, divida o dataset entre data/train e data/val (dataset de validaÃ§Ã£o).

Os checkpoints do modelo treinado ficarÃ£o em checkpoints/

### 2. ColorizaÃ§Ã£o (InferÃªncia)

Para colorizar uma imagem em tons de cinza, forneÃ§a o caminho para a imagem de entrada e para o modelo prÃ©-treinado na seÃ§Ã£o indicada no jupyter notebook.


## ğŸ“Š Resultados

O modelo treinado demonstrou uma forte capacidade de generalizaÃ§Ã£o. Mesmo treinado exclusivamente com imagens de cÃ£es, foi capaz de colorir de forma convincente outras espÃ©cies de animais e objetos, indicando que a rede aprendeu associaÃ§Ãµes robustas entre texturas, formas e cores prototÃ­picas.

A anÃ¡lise de interpretabilidade com mapas de saliÃªncia confirmou que o modelo foca em caracterÃ­sticas semanticamente relevantes (como olhos e focinhos) para tomar suas decisÃµes de colorizaÃ§Ã£o.
